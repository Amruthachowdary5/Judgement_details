{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q instructor requests pypdf google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = instructor.patch(OpenAI(api_key=\"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\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as 'IPR.pdf'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Open a file in binary write mode and write the content from the response\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"File downloaded successfully and saved as '{save_path}'\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage:\n",
    "url = 'https://www.livelaw.in/pdf_upload/iprs-470607.pdf'  # Replace with your URL\n",
    "save_path =\"IPR.pdf\"  # Path where the file will be saved\n",
    "\n",
    "download_file(url, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import uuid\n",
    "\n",
    "reader = PdfReader(\"IPR.pdf\")\n",
    "dtext = ''\n",
    "for page_number in range(5):\n",
    "    dtext += reader.pages[page_number].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2985"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import datetime\n",
    "\n",
    "key = 'AIzaSyC29LbOXv4_AqEkVcaizn-wQZqNhTZY9No'  #@param {type: \"string\"}\n",
    "\n",
    "genai.configure(api_key=key)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "tokens = model.count_tokens(dtext)\n",
    "tokens.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import uuid\n",
    "\n",
    "reader = PdfReader(\"IPR.pdf\")\n",
    "text = ''\n",
    "for page_number in range(len(reader.pages)):\n",
    "    text += reader.pages[page_number].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36900"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import datetime\n",
    "\n",
    "key = 'AIzaSyC29LbOXv4_AqEkVcaizn-wQZqNhTZY9No'  #@param {type: \"string\"}\n",
    "\n",
    "genai.configure(api_key=key)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "tokens = model.count_tokens(text)\n",
    "tokens.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks=text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokens.total_tokens >= 15000:\n",
    "   chunks = text_splitter.split_text(text)\n",
    "   print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ask Junior\\Instructor_Extract\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "key = 'AIzaSyC29LbOXv4_AqEkVcaizn-wQZqNhTZY9No'  #@param {type: \"string\"}\n",
    "\n",
    "genai.configure(api_key=key)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "model_type = 'gemini'\n",
    "\n",
    "def query_gemini_model(\n",
    "    prompt: str,\n",
    "    retries: int = 10,\n",
    ") -> str:\n",
    "  while True and retries > 0:\n",
    "    try:\n",
    "      response = model.generate_content(prompt)\n",
    "      text_response = response.text.replace(\"**\", \"\")\n",
    "      return text_response\n",
    "    except Exception as e:\n",
    "      print(f'{datetime.datetime.now()}: query_gemini_model: Error: {e}')\n",
    "      print(f'{datetime.datetime.now()}: query_gemini_model: Retrying after 5 seconds...')\n",
    "      retries -= 1\n",
    "      time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Using OpenAI GPT model (DO NOT run the next cell if using GPT)\n",
    "\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "OpenAI_key = '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'  #@param {type: \"string\"}\n",
    "\n",
    "model_type = 'gpt'\n",
    "\n",
    "def query_gpt_model(\n",
    "    prompt: str,\n",
    "    seconds_to_reset_tokens: float = 30.0,\n",
    ") -> str:\n",
    "    \n",
    "    client = OpenAI(api_key=OpenAI_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except openai.RateLimitError as e:\n",
    "        print({e.message})\n",
    "        time.sleep(seconds_to_reset_tokens)\n",
    "    except openai.APIError as e:\n",
    "        print({e.message})\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "\n",
    "def query_mistral(prompt):\n",
    "    api_base = \"https://openrouter.ai/api/v1\"\n",
    "    token = \"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\"\n",
    "    url = f\"{api_base}/chat/completions\"\n",
    "    body = {\n",
    "        \"model\": \"anthropic/claude-instant-1.0\", \n",
    "        \"temperature:\": 0.4, \n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "    }\n",
    "    response = requests.post(url, headers={\"Authorization\": f\"Bearer {token}\"}, json=body)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    shortened_passage = data['choices'][0]['message']['content']\n",
    "    \n",
    "    return shortened_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_shorten_template = \"\"\"\n",
    "Please shorten the following passage.\n",
    "Just give me a shortened version. DO NOT explain your reason.\n",
    "\n",
    "Passage:\n",
    "{}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def passage_shorten(passage: str) -> str:\n",
    "  prompt = prompt_shorten_template.format(passage)\n",
    "  shortened_passage = query_gpt_model(prompt)\n",
    "  return shortened_passage\n",
    "\n",
    "\n",
    "pages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:12<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    order, data = chunk\n",
    "    shortened_passage = passage_shorten(data)\n",
    "    return order, shortened_passage\n",
    "\n",
    "# Use ThreadPoolExecutor with max_workers=5 to limit concurrency\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(process_chunk, (order, data)) for order, data in enumerate(chunks)]\n",
    "\n",
    "    # Use tqdm to display a progress bar\n",
    "    pages = []\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        order, result = future.result()\n",
    "        pages.append((order, result))\n",
    "\n",
    "# Sort the pages based on the order\n",
    "pages.sort(key=lambda x: x[0])\n",
    "pages = [page[1] for page in pages]\n",
    "\n",
    "# Now 'pages' contains the processed chunks in the original order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = \"\\n\".join(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    IRAC_PROMPT = f\"\"\"\n",
    "Analyse this judgement using the framework provided. There are 4 components to this framework:\n",
    "Issues: Here you will identify who the Appellant and the Respondent are, what is the factual background that led to the matter reaching the Supreme Court, and what contentions and arguments were made by both sides. Please be detailed and include all relevant factual information.\n",
    "Rule: Here you will identify the statutes and legal provisions that are being used in the judgement. Please specify the name of the statute and the provisions, along with the contents.\n",
    "Analysis: Here, I would like you to identify and summarize the analysis of the court in the judgement. Please make a list of all the judgements cited by the Court along with the law laid down in those judgements. Then summarize the analysis and reasoning of the court .\n",
    "Conclusion: Here I would like you to identify the final decision of the court. That is whether the appeal was allowed or not, or any other relevant findings of the court or costs or penalties imposed.\n",
    "\n",
    "\n",
    "Judgment:\n",
    "{combined_text}\n",
    "\"\"\"\n",
    "    result = query_gemini_model(IRAC_PROMPT)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 10:34:14.780858: query_gemini_model: Error: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "2024-03-07 10:34:14.780858: query_gemini_model: Retrying after 5 seconds...\n",
      "Issues:\n",
      "- Appellants: Indian Performing Right Society Ltd. (IPRS)\n",
      "- Respondents: Rajasthan Patrika Pvt. Ltd. and Music Broadcast Ltd.\n",
      "- Factual Background:\n",
      "   - IPRS filed lawsuits against the defendants seeking interim reliefs based on amendments to the Copyright Act.\n",
      "   - IPRS claimed the amendments gave authors new rights, while the defendants argued they were merely clarificatory.\n",
      "   - The parties had entered into agreements for radio broadcasts, and legal proceedings followed.\n",
      "   - The Copyright Act was amended in 2012, impacting the case.\n",
      "   - IPRS requested data on songs played by the defendants' radio stations.\n",
      "   - IPRS filed suits in 2022 seeking interim reliefs against the defendants.\n",
      "\n",
      "Rule:\n",
      "- Copyright Act, 1957\n",
      "   - Section 13: Copyright in Original Literary, Dramatic, Musical and Artistic Works\n",
      "   - Section 14: Copyright in Cinematograph Films\n",
      "   - Section 17: Right to Perform and Communicate Works\n",
      "   - Section 18: Rights of Performance in Sound Recordings\n",
      "   - Section 19: Rights of Communication of Sound Recordings\n",
      "\n",
      "Analysis:\n",
      "- The court analyzed the amendments to the Copyright Act in 2012 and their impact on the case.\n",
      "- The plaintiff (IPRS) argued that the amendments justified their case for interim reliefs, despite previous court decisions.\n",
      "- The defendants argued that the amendments were clarificatory and did not change the law.\n",
      "- The court considered the following case laws:\n",
      "   - IPRS vs. Entertainment Network (India) Limited\n",
      "   - IPRS vs. Eastern Indian Motion Pictures Association\n",
      "- The court held that the amendments in Sections 17, 18, and 19 of the Copyright Act altered the interpretation of copyright law, even though Sections 13 and 14 remained unchanged.\n",
      "- The court found that the added provisos created substantive rights for authors, particularly regarding royalties.\n",
      "- The court agreed that the plaintiff (IPRS) had a strong case under the amended Copyright Act.\n",
      "\n",
      "Conclusion:\n",
      "- The appeal was allowed.\n",
      "- The court granted interim relief in favor of IPRS, restraining the defendants from infringing on the copyrights of authors and requiring them to announce the names of authors and performers.\n"
     ]
    }
   ],
   "source": [
    "information = summarize(text)\n",
    "print(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Court': 'Bombay High Court',\n",
       " 'Petitioner': ['Indian Performing Right Society Limited'],\n",
       " 'Respondent': ['Rajasthan Patrika Pvt. Ltd.', 'Music Broadcast Limited'],\n",
       " 'Neural_Citation_number': ['2023:BHC-OS:3623'],\n",
       " 'SCR_Citation': '[2023] BHC-OS 3623',\n",
       " 'Judgement_delivered_by': 'MANISH PITALE, J.',\n",
       " 'Date_of_Judgement': '28th APRIL, 2023'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "from datetime import date\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal\n",
    "from typing import List\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI(api_key=\"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\"))\n",
    "\n",
    "\n",
    "class judgement1(BaseModel):\n",
    "    Court : str\n",
    "    Petitioner : List[str] = Field(\n",
    "        description=\"list all the petitioner involved in this case in an order with number.\"\n",
    "    )\n",
    "    Respondent : List[str] = Field(\n",
    "        description=\"list all the respondents involved in this case in an order with number.\"\n",
    "    )\n",
    "    Neural_Citation_number : List[str] = Field(\n",
    "        description= \"List all the citation numbers in an order as it is in the judgement and also write the text with citation number but don't provide additional information, for example: 2024 INSC 94.\"\n",
    "    )\n",
    "    SCR_Citation : str = Field(\n",
    "        description= \"Specify the citation number don't include other information, for example:[2024] 1 S.C.R. 1.\"\n",
    "    )\n",
    "    Judgement_delivered_by :str= Field(\n",
    "        description=\"Mention all the judges who delivered the judgement.\"\n",
    "    )\n",
    "    Date_of_Judgement : str= Field(\n",
    "        description= \"Write the date in such a way that it is mentioned in the judgement.\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    def information(self):\n",
    "        print(\n",
    "            f\" {self.Court}, {self.Petitioner}, {self.Respondent}, {self.Neural_Citation_number}\"\n",
    "        )\n",
    "   \n",
    "\n",
    "\n",
    "resp1 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[{\"role\": \"user\", \"content\": dtext}],\n",
    "    response_model=judgement1,\n",
    ")\n",
    "resp1.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Act': ['Copyright Act, 1957'],\n",
       " 'Rule': ['Section 13: Copyright in Original Literary, Dramatic, Musical and Artistic Works',\n",
       "  'Section 14: Copyright in Cinematograph Films',\n",
       "  'Section 17: Right to Perform and Communicate Works',\n",
       "  'Section 18: Rights of Performance in Sound Recordings',\n",
       "  'Section 19: Rights of Communication of Sound Recordings'],\n",
       " 'Amendments': ['Amended in 2012'],\n",
       " 'category': ['Intellectual_Property_Rights', 'Copyrights'],\n",
       " 'Disposal_Nature': ['Appeal Allowed'],\n",
       " 'Order_or_Judgement': ['Judgment']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal\n",
    "from typing import List\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI(api_key=\"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\"))\n",
    "\n",
    "LABELS = Literal[\"Criminal_Appeal\",\n",
    "\"Civil_Suit\",\n",
    "\"Civil_Appeal\",\n",
    "\"Civil_Writ_Petition\",\n",
    "\"Arbitration_Case\",\n",
    "\"Contempt_Appeals\",\n",
    "\"Company_Appeal\",\n",
    "\"Central_Excise_Appeal\"\n",
    "\"Income_Tax_Appeal\",\n",
    "\"Matrimonial_Reference\",\n",
    "\"Probate\",\n",
    "\"Wealth_Tax_Appeal\",\n",
    "\"Commercial_Disputes\",\n",
    "\"Motor_Accident_Claims\",\n",
    "\"Labor_Matters\",\n",
    "\"Land_Acquisition_Matters\",\n",
    "\"Tax_Assessments\",\n",
    "\"Election_Disputes\",\n",
    "\"Intellectual_Property_Rights\",\n",
    "\"Patents\",\n",
    "\"Copyrights\",\n",
    "\"Trademarks\",\n",
    "\"Trade_secrets\",\n",
    "\"Property_Law\",\n",
    "\"Business_Law\",\n",
    "\"Contract_Act\"\n",
    "]\n",
    "\n",
    "class judgement2(BaseModel):\n",
    "    Act : List[str] = Field(\n",
    "        description= \"Just mention the act that supports the judgement don't include other information.\"\n",
    "    )\n",
    "    Rule : List[str]= Field(\n",
    "        description= \"List all the rules that are specified in the summary and don't mention any other information.\"\n",
    "    )\n",
    "    Amendments : List[str]= Field(\n",
    "        description= \"Mention all the amendments that support this judgement in a structured format, If there are no ammendments write None.\"\n",
    "    )\n",
    "    category  : List[LABELS]= Field(\n",
    "        description=\"select all the case types that support the judgement in a structured format\",\n",
    "    )\n",
    "    Disposal_Nature : List[str] = Field(\n",
    "        description=\"Specify the appeal information of this case in a single word, for example: Appeal Dismesed, Appeal Allowed.\"\n",
    "    )\n",
    "    Order_or_Judgement : List[str] = Field(\n",
    "        description=\"Specify that whether the judge mentioned order or judgement.\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    def information(self):\n",
    "        print(\n",
    "            f\" {self.Rule}, {self.Section}, {self.copyright}, {self.Amendments}, {self.category}, {self.precedence}\"\n",
    "        )\n",
    "   \n",
    "\n",
    "\n",
    "resp2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[{\"role\": \"user\", \"content\": information}],\n",
    "    response_model=judgement2,\n",
    ")\n",
    "resp2.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"File downloaded successfully and saved as '{save_path}'\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = ''\n",
    "    for page_number in range(len(reader.pages)):\n",
    "        text += reader.pages[page_number].extract_text()\n",
    "    return text\n",
    "\n",
    "def split_text_into_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=5000, chunk_overlap=100)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def passage_shorten(passage: str) -> str:\n",
    "    prompt_shorten_template = \"\"\"\n",
    "    Please shorten the following passage.\n",
    "    Just give me a shortened version. DO NOT explain your reason.\n",
    "\n",
    "    Passage:\n",
    "    {}\n",
    "    \"\"\"\n",
    "    prompt = prompt_shorten_template.format(passage)\n",
    "    shortened_passage = query_gpt_model(prompt)\n",
    "    return shortened_passage\n",
    "\n",
    "def summarize(text):\n",
    "    IRAC_PROMPT = f\"\"\"\n",
    "    Analyse this judgement using the framework provided. There are 4 components to this framework:\n",
    "    Issues: Here you will identify who the Appellant and the Respondent are, what is the factual background that led to the matter reaching the Supreme Court, and what contentions and arguments were made by both sides. Please be detailed and include all relevant factual information.\n",
    "    Rule: Here you will identify the statutes and legal provisions that are being used in the judgement. Please specify the name of the statute and the provisions, along with the contents.\n",
    "    Analysis: Here, I would like you to identify and summarize the analysis of the court in the judgement. Please make a list of all the judgements cited by the Court along with the law laid down in those judgements. Then summarize the analysis and reasoning of the court .\n",
    "    Conclusion: Here I would like you to identify the final decision of the court. That is whether the appeal was allowed or not, or any other relevant findings of the court or costs or penalties imposed.\n",
    "\n",
    "    Judgment:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    result = query_gpt_model(IRAC_PROMPT)\n",
    "    return result\n",
    "\n",
    "def process_judgement(url, save_path):\n",
    "    download_file(url, save_path)\n",
    "    pdf_text = extract_text_from_pdf(save_path)\n",
    "    tokens = model.count_tokens(pdf_text)\n",
    "    tokens.total_tokens\n",
    "    combined_text = \"\"\n",
    "    if tokens.total_tokens >= 15000:\n",
    "        chunks = split_text_into_chunks(pdf_text)\n",
    "        print(len(chunks))\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures = [executor.submit(passage_shorten, data) for data in chunks]\n",
    "\n",
    "        # Use tqdm to display a progress bar\n",
    "            processed_chunks = []\n",
    "            for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "                processed_chunks.append(future.result())\n",
    "    \n",
    "        combined_text = ''.join(processed_chunks)\n",
    "    else:\n",
    "        combined_text = pdf_text\n",
    "\n",
    "    summary_result = summarize(combined_text)\n",
    "    return summary_result\n",
    "\n",
    "\n",
    "def extract_pages(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    dtext = ''\n",
    "    for page_number in range(10):\n",
    "        dtext += reader.pages[page_number].extract_text()\n",
    "    return dtext\n",
    "\n",
    "\n",
    "client = instructor.patch(OpenAI(api_key=\"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\"))\n",
    "\n",
    "class judgement1(BaseModel):\n",
    "    Court : str\n",
    "    Petitioner : List[str] = Field(\n",
    "        description=\"list all the petitioner involved in this case in an order with number.\"\n",
    "    )\n",
    "    Respondent : List[str] = Field(\n",
    "        description=\"list all the respondents involved in this case in an order with number.\"\n",
    "    )\n",
    "    Neural_Citation_number : List[str] = Field(\n",
    "        description= \"List all the citation numbers in an order as it is in the judgement and also write the text with citation number but don't provide additional information, for example: 2024 INSC 94.\"\n",
    "    )\n",
    "    SCR_Citation : str = Field(\n",
    "        description= \"Specify the citation number don't include other information, for example:[2024] 1 S.C.R. 1.\"\n",
    "    )\n",
    "    Judgement_delivered_by :str= Field(\n",
    "        description=\"Mention all the judges who delivered the judgement.\"\n",
    "    )\n",
    "    Date_of_Judgement : str= Field(\n",
    "        description= \"Write the date in such a way that it is mentioned in the judgement.\"\n",
    "    )\n",
    "    \n",
    "    def information(self):\n",
    "        return f\"{self.Court}, {self.Petitioner}, {self.Respondent}, {self.Neural_Citation_number}\"\n",
    "\n",
    "LABELS = Literal[\"Criminal_Appeal\",\n",
    "\"Civil_Suit\",\n",
    "\"Civil_Appeal\",\n",
    "\"Civil_Writ_Petition\",\n",
    "\"Arbitration_Case\",\n",
    "\"Contempt_Appeals\",\n",
    "\"Company_Appeal\",\n",
    "\"Central_Excise_Appeal\"\n",
    "\"Income_Tax_Appeal\",\n",
    "\"Matrimonial_Reference\",\n",
    "\"Probate\",\n",
    "\"Wealth_Tax_Appeal\",\n",
    "\"Commercial_Disputes\",\n",
    "\"Motor_Accident_Claims\",\n",
    "\"Labor_Matters\",\n",
    "\"Land_Acquisition_Matters\",\n",
    "\"Tax_Assessments\",\n",
    "\"Election_Disputes\",\n",
    "\"Intellectual_Property_Rights\",\n",
    "\"Patents\",\n",
    "\"Copyrights\",\n",
    "\"Trademarks\",\n",
    "\"Trade_secrets\",\n",
    "\"Property_Law\",\n",
    "\"Business_Law\",\n",
    "\"Contract_Act\"\n",
    "]\n",
    "\n",
    "class judgement2(BaseModel):\n",
    "    Act : List[str] = Field(\n",
    "        description= \"Just mention the act that supports the judgement don't include other information.\"\n",
    "    )\n",
    "    Rule : List[str]= Field(\n",
    "        description= \"List all the rules that are specified in the summary and don't mention any other information.\"\n",
    "    )\n",
    "    Amendments : List[str]= Field(\n",
    "        description= \"Mention all the amendments that support this judgement in a structured format, If there are no ammendments write None.\"\n",
    "    )\n",
    "    category  : List[LABELS] = Field(\n",
    "        description=\"select all the case types that support the judgement in a structured format\",\n",
    "    )\n",
    "    Disposal_Nature : List[str] = Field(\n",
    "        description=\"Specify the appeal information of this case in a single word, for example: Appeal Dismesed, Appeal Allowed.\"\n",
    "    )\n",
    "    Order_or_Judgement : List[str] = Field(\n",
    "        description=\"Specify that whether the judge mentioned order or judgement.\"\n",
    "    )\n",
    "    \n",
    "    def information(self):\n",
    "        return f\"{self.Rule}, {self.category}, {self.Disposal_Nature}, {self.Order_or_Judgement}\"\n",
    "\n",
    "\n",
    "def get_judgement_responses(dtext, dsum):\n",
    "    resp1 = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": dtext}],\n",
    "        response_model=judgement1,\n",
    "    )\n",
    "    resp2 = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": dsum}],\n",
    "        response_model=judgement2,\n",
    "    )\n",
    "\n",
    "    # Retrieve and print completions\n",
    "    completion1 = resp1\n",
    "    completion2 = resp2\n",
    "\n",
    "    return completion1\n",
    "    return completion2\n",
    "\n",
    "    print(\"Basic Deatils:\")\n",
    "    print(completion1)\n",
    "    print(\"Specific Details:\")\n",
    "    print(completion2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as 'Major.pdf'\n",
      "Basic Deatils:\n",
      "Court='Supreme Court of India' Petitioner=['Major Gen. Darshan Singh (D) By Lrs.', 'Anr.'] Respondent=['Brij Bhushan Chaudhary (D) by Lrs.'] Neural_Citation_number=['2024 INSC 157'] SCR_Citation='Civil Appeal no.9360 of 2013' Judgement_delivered_by='ABHAY S. OKA, J.' Date_of_Judgement='March 1, 2024'\n",
      "Specific Details:\n",
      "Act=['Specific Relief Act, 1963'] Rule=['Section 16(c)', 'Section 22(1)(a)', 'Hardeo Rai v. Sakuntala Devi', 'Surinder Singh v. Kapoor Singh', 'Rachakonda Narayana v. Ponthala Parvathamma'] Amendments=['None'] category=['Civil_Suit'] Disposal_Nature=['Partially Allowed'] Order_or_Judgement=['Judgement']\n",
      "Issues:\n",
      "Appellant: Major Gen. Darshan Singh (D) By Lrs. & Anr.\n",
      "Respondent: Brij Bhushan Chaudhary (D) by Lrs.\n",
      "The factual background involves a suit agreement for the sale of a property between the parties. The appellant claimed that there were negotiations to reduce the price of the property, possession was handed over, and the defendant changed his mind leading to non-compliance with the agreement. The respondent contended that the property was HUF property, and possession was not given to the appellants. The Trial Court awarded damages but denied specific performance. The District Court upheld the decision, and the High Court confirmed it based on the property being HUF property.\n",
      "\n",
      "Rule:\n",
      "The judgment refers to the Specific Relief Act, 1963. Section 16(c) was cited regarding readiness and willingness for specific performance. Section 22(1)(a) allows for a decree of partition in addition to specific performance. The court also referred to previous cases such as Hardeo Rai v. Sakuntala Devi, Surinder Singh v. Kapoor Singh, and Rachakonda Narayana v. Ponthala Parvathamma to support their analysis.\n",
      "\n",
      "Analysis:\n",
      "The court analyzed the conduct of the plaintiffs, finding that they withheld crucial information about the property being HUF property and made false statements regarding possession and price negotiation in their pleadings. Based on this conduct, the court held that the plaintiffs were not entitled to specific performance. However, they modified the damages awarded to include interest post the Trial Court's decree.\n",
      "\n",
      "Conclusion:\n",
      "The appeal was partially allowed, with the modification of interest on damages. No costs were imposed. The court held that the plaintiffs' conduct disentitled them to the relief of specific performance.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://main.sci.gov.in/supremecourt/2010/38234/38234_2010_7_1501_51005_Judgement_01-Mar-2024.pdf'\n",
    "save_path =\"Major.pdf\"\n",
    "pdf_text_ten = extract_pages(save_path)\n",
    "judgement_summary = process_judgement(url, save_path)\n",
    "dtext = pdf_text_ten\n",
    "dsum = judgement_summary\n",
    "get_judgement_responses(dtext, dsum)\n",
    "print(judgement_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
